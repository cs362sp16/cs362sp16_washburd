My tester had excellent coverage.  In just 2 runs, using the seeds 2 and 42, I had over 80% coverage of both my code and the directory I chose to compare with (edwardrh, in case you wanted to know).  This does not mean my method was good by any means, but it does imply that it is playing each of the cards often enough that it gains massive coverage in few trials.

The differences that popped up are, I believe, due to the bugs I put in back in assignment 1.  I lowered the cards drawn from Smithy from 3 to 2, and made it so you do not recieve your extra turn from Outpost.  When running the seed 2, I noticed the game did not have either of these cards, but 42 contained a Smithy and, reading the test.tmp and test2.tmp, I saw their divergence begin after having played a Smithy.  Other seeds that involved an outpost similarly showed a divergence after having been played.  Interestingly, I could not locate whatever bugs were on his code when the game lacked both my bugged cards, though he could have gone for output bugs, something I completely circumvented in this implementation, only looking at raw numbers.

This is absolutely not an ideal method of testing because if our code were to have any other differences, it would make comparison impossible.  Additionally, it is easily possible we could have got all the same things incorrect.  Perhaphs within a company working on the same codebase this could be useful to find bugs someone overlooked, but at that point it would have been quicker and more efficient to have done paired programming in the first place, rather than letting 2 individual engineers create their own crazy solutions.
